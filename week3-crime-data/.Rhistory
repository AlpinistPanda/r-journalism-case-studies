sum(is.na(h2015_joined$Homcides2014))
h2014_joined <- left_join(h2014, h2015, by=c("State", "City"))
View(h2014_joined)
h2015 <- select(h2015, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
View(h2015_joined)
---
title: "Investigating homicide statistics"
author: "Andrew Ba Tran"
date: "1/29/2017"
output: html_document
---
Importing different data sets, calculations
Goal: Dealing with Excel files, analyzing data, adjusting for population.
Donald Trump promised to save America from the hellish wave of crime and disorder in his inaugural address.
"The crime and the gangs and the drugs that have stolen too many lives and robbed our country of so much unrealized potential," said President Trump. "This American carnage stops right here and stops right now."
A statement on the White House website lays out the foundation for their claims.
![White House statement on crime](images/trump1.png)
The Trump adminstration alleges that
* In 2015, homicides increased by 17% in America’s fifty largest cities
* That’s the largest increase in 25 years
* In our nation’s capital, killings rose by 50 percent over the past four years
* There were thousands of shootings in Chicago last year alone
Trump does not have a great track record when it comes to [accurate representation](https://www.washingtonpost.com/graphics/politics/2016-election/trump-charts/) of data.
So think like a journalist.
Is this true? How can it be verified?
With data on homicides. Where can we get that data?
Reframe that question.
Who would collect data on homicides and why? (Think local then go wider.)
* Police departments
+ To arrest those responsible
* City governments
+ To track population, public policy adjustments
* Local news media
+ To report on events that affect the public
* The Justice Department
+ To track local, regional, state trends
* The Federal Bureau of Investigation
+ To track local statistics
* Insurance, real estate companies, businesses
+ To measure risk and likelihood of crime in an area to set rates
How can you get the data from them?
* Call them up
* Check online
* File a FOIA request
Let's use the FBI's Uniform Crime Reporting Statistics
They've collected data from police departments across the country for decades.
Each year they create a new report. However, their overall [table builder tool](https://www.ucrdatatool.gov/) that lets people pull data across several years only goes up to 2014. It doesn't have the latest 2015 data.
But that's alright for now.
To verify this first claim "In 2015, homicides increased by 17% in America’s fifty largest cities" we need the 2015 and 2014 data to compare to each other.
We'll need a list of the 50 largest cities and we'll need homicide totals from 2014 and 2015 to measure the percent change.
The 2015 data is [here](https://ucr.fbi.gov/crime-in-the-u.s/2015/crime-in-the-u.s.-2015) and the 2014 data is [here](https://ucr.fbi.gov/crime-in-the-u.s/2014/crime-in-the-u.s.-2014).
It's not the most intuitive site to navigate, so I'll point you in the right direction.
Click the 'Download Excel' sheet on [Table 8](https://ucr.fbi.gov/crime-in-the-u.s/2015/crime-in-the-u.s.-2015/tables/table-8/table_8_offenses_known_to_law_enforcement_by_state_by_city_2015.xls/view) of the 2015 data and save it to your **data** folder.
Do the same for the 2014 data on [Table 8](https://ucr.fbi.gov/crime-in-the-u.s/2014/crime-in-the-u.s.-2014/tables/table-8/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2014.xls/view).
![You should now have two Excel spreadsheets](images/fbi1.png)
Let's load them in and see what they look like.
We'll use the [**readxl**](https://github.com/hadley/readxl) package.
```{r reading_data, message=F, warning=F}
library(readxl)
h2014 <- read_excel("data/table-8.xls", sheet=1)
```
![This is what it looks when you **View()** the dataframe in RStudio.](images/fbi2.png)
Problems, right?
![That's because it reflects the formating of the Excel spreadsheet.](images/fbi3.png)
It's not the tidy data structure we're used to working with in R.
There are too many cells with NAs.
We have to clean it up.
```{r reading_data2, message=F, warning=F}
#Fortunately, we can tell the read_excel() function to skip to a certain row when bringing in data
h2014 <- read_excel("data/table-8.xls", sheet=1, skip=3)
```
![Better.](images/fbi4.png)
The columns have been named correctly, but it's good practice to change column names so they're syntactically valid. This means no spaces or odd characters.
To do that, use the **make.names()** function.
```{r reading_data3}
colnames(h2014) <- make.names(colnames(h2014))
```
![Now, were talking.](images/fbi5.png)
But now we need to replace the `NA`s in the **State** column.
There might be a quicker way to do it, but for now, I'm going to show you a quick loop to do it.
```{r reading_data4}
# What this loop does
# For every row between 1 and the the total number of rows in h2014 dataframe
for (i in 1:nrow(h2014)) {
# If the cell in State is blank,
if(is.na(h2014$State[i])) {
# Then fill it with the value of the State cell previous to it
h2014$State[i]<-h2014$State[i-1]
}
}
#This way the cell will be filled with the last value, which logically, is the state identifier.
```
![Excellent.](images/fbi6.png)
Now, let's do this to the 2015 data by judge adjusting the code from above.
```{r reading_data5}
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
```
Great, we've got two data sets with homicides for all cities across the country.
Let's narrow the 2015 data down to the 50 largest cities (Fortunately, the data includes population). And then we'll join it to the 2014 data.
We'll use the **dplyr** package.
```{r population_filter, warning=F, message=F}
library(dplyr)
# Arranging by population in descending order
h2015 <- arrange(h2015, desc(Population))
# Grabbing just the first 50 cities
h2015_50 <- h2015[1:50,]
# Prepping the two dataframes for joining
h2015_50 <- select(h2015_50, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2014 <- select(h2014, State, City, Homicides2014=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
```
Did that work?
```{r top5}
head(h2015_joined)
```
Hm, it didn't join successfully on some. What's up with that?
Let's take a look at what's going on in New York.
![Aha](images/fbi7.png)
It looks like a number of the data points have footnote numbers (Dammit, Excel!)
We have to use regex to clean out those numeric characters.
```{r more_cleaning}
# This library a function I'll use to trim trailing spaces
library(stringr)
# These commands get rid of numbers and commas
h2014$City <- gsub('[0-9]+', '', h2014$City)
h2014$City <- gsub(',', '', h2014$City)
h2014$City <- str_trim(h2014$City)
h2014$State <- gsub('[0-9]+', '', h2014$State)
h2014$State <- gsub(',', '', h2014$State)
h2014$State <- str_trim(h2014$State)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
```
Alright, how many `NA` cells are there now? We can check by typing `sum(is.na(h2015_joined$Homicides2014))` and we'll know there are `r sum(is.na(h2015_joined$Homicides2014))` blank values.
Why is that?
Well, I won't make you dig around further, but if you did, you'd see that it was because most of those cities weren't in both years.
As in Fort Worth had data for 2015 but not for 2014.
In all, Honolulu, Fort Worth, Tucson, and Wichita were not present and thus could not be successfully joined.
Nashville was present in both data sets but did not join successfully because in 2015, officials called it "Nashville Metropolitan" while in 2014, it was called just "Nashville".
**This is the frustrating thing about working with data.**
**It can be incomplete or inconsistent and takes a long time to prepare it before we can analyze it.**
OK, let's do what we can.
```{r more_cleaning2s}
# We can at least fix Nashville quickly
h2014$City <- gsub('Nashville', 'Nashville Metropolitan', h2014$City)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
```
Alright, we're down to just four missing cities.
Let's do some math knowing the data is incomplete just for fun.
```{r math1}
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
```
So with four towns missing, there were `r total_homicides_2014` homicides in 2014 and `r total_homicides_2015` homicides in 2015.
That's a percent change of `r percent_change_2015`, which is close to the 17 percent that Trump alleges. But with homides missing from four towns, the percent change is exaggerated.
Let's try it one more way and try to make it as complete as possible.
```{r more_cleaning2s}
# Let's filter to the largest 50 cities that have both 2014 and 2015 data
h2015 <- select(h2015, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- filter(h2015_joined, !is.na(Homicides2014))
```
View(h2015_joined)
h2014 <- read_excel("data/table-8.xls", sheet=1)
h2014 <- read_excel("data/table-8.xls", sheet=1, skip=3)
colnames(h2014) <- make.names(colnames(h2014))
# For every row between 1 and the the total number of rows in h2014 dataframe
for (i in 1:nrow(h2014)) {
# If the cell in State is blank,
if(is.na(h2014$State[i])) {
# Then fill it with the value of the State cell previous to it
h2014$State[i]<-h2014$State[i-1]
}
}
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
library(dplyr)
# Arranging by population in descending order
h2015 <- arrange(h2015, desc(Population))
# Grabbing just the first 50 cities
h2015_50 <- h2015[1:50,]
# Prepping the two dataframes for joining
h2015_50 <- select(h2015_50, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2014 <- select(h2014, State, City, Homicides2014=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
head(h2015_joined)
# This library a function I'll use to trim trailing spaces
library(stringr)
# These commands get rid of numbers and commas
h2014$City <- gsub('[0-9]+', '', h2014$City)
h2014$City <- gsub(',', '', h2014$City)
h2014$City <- str_trim(h2014$City)
h2014$State <- gsub('[0-9]+', '', h2014$State)
h2014$State <- gsub(',', '', h2014$State)
h2014$State <- str_trim(h2014$State)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
h2014$City <- gsub('Nashville', 'Nashville Metropolitan', h2014$City)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
h2015 <- select(h2015, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- filter(h2015_joined, !is.na(Homicides2014))
View(h2015_joined)
View(h2015_joined)
h2015_joined <- filter(h2015_joined, row_num()<=50)
h2015_joined <- h2015[1:50,]
View(h2015_joined)
h2014 <- read_excel("data/table-8.xls", sheet=1)
h2014 <- read_excel("data/table-8.xls", sheet=1, skip=3)
colnames(h2014) <- make.names(colnames(h2014))
# What this loop does
# For every row between 1 and the the total number of rows in h2014 dataframe
for (i in 1:nrow(h2014)) {
# If the cell in State is blank,
if(is.na(h2014$State[i])) {
# Then fill it with the value of the State cell previous to it
h2014$State[i]<-h2014$State[i-1]
}
}
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
h2015 <- arrange(h2015, desc(Population))
# Grabbing just the first 50 cities
h2015_50 <- h2015[1:50,]
# Prepping the two dataframes for joining
h2015_50 <- select(h2015_50, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2014 <- select(h2014, State, City, Homicides2014=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
# These commands get rid of numbers and commas
h2014$City <- gsub('[0-9]+', '', h2014$City)
h2014$City <- gsub(',', '', h2014$City)
h2014$City <- str_trim(h2014$City)
h2014$State <- gsub('[0-9]+', '', h2014$State)
h2014$State <- gsub(',', '', h2014$State)
h2014$State <- str_trim(h2014$State)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
h2014$City <- gsub('Nashville', 'Nashville Metropolitan', h2014$City)
# Now let's try to bring the 2015 and 2014 dataframes together again
h2015_joined <- left_join(h2015_50, h2014, by=c("State", "City"))
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- h2015[1:50,]
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
View(h2015_joined)
View(h2014)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
View(h2015_joined)
h2015_joined <- h2015[1:50,]
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
h2015_joined <- h2015_joined[1:50,]
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
total_homicides_2014
View(h2015_joined)
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- h2015_joined[1:50,]
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
percent_change_2015
h2015_joined <- filter(h2015_joined, !is.na(Homicides2014))
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- filter(h2015_joined, !is.na(Homicides2014))
h2015_joined <- h2015_joined[1:50,]
View(h2015_joined)
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
percent_change_2015
h2015_joined$percent_change <- round((h2015_joined$$Homicides2015- h2015_joined$$Homicides2014)/h2015_joined$$Homicides2014*100,2)
h2015_joined$percent_change <- round((h2015_joined$Homicides2015- h2015_joined$Homicides2014)/h2015_joined$Homicides2014*100,2)
View(h2015_joined)
View(h2014)
sum1 <- sum(h2014$Homicides2014)
sum2 <- sum(h2015$Homicides2015)
sum1
sum2
sum2 <- sum(h2015$Homicides2015, na.rm=T)
sum2
sum1 <- sum(h2014$Homicides2014, na.rm=T)
sum1
11496-10256
1240/10256
h2015_joined <- left_join(h2015, h2014, by=c("State", "City"))
h2015_joined <- filter(h2015_joined, !is.na(Homicides2014))
total_homicides_2014 <- sum(h2015_joined$Homicides2014, na.rm=T)
total_homicides_2015 <- sum(h2015_joined$Homicides2015, na.rm=T)
# Percent change
percent_change_2015 <- round((total_homicides_2015- total_homicides_2014)/total_homicides_2014*100,2)
percent_change_2015
trends <- read.csv("data/LocalCrimeTrendsInOneVar.csv", stringsAsValues=F)
trends <- read.csv("data/LocalCrimeTrendsInOneVar.csv", stringsAsValues=F)
trends <- read.csv("data/LocalCrimeTrendsInOneVar.csv")
library(readr)
trends <- read_csv("data/LocalCrimeTrendsInOneVar.csv")
View(trends)
?read.csv
trends <- read.csv("data/LocalCrimeTrendsInOneVar.csv", stringsAsFactors=F, skip=4)
View(trends)
View(trends)
trends <- trends[1:82,]
View(trends)
trends <- read.csv("data/LocalCrimeTrendsInOneVar.csv", stringsAsFactors=F, skip=4)
View(trends)
trends <- trends[1:82,]
View(trends)
trends$X <- NULL
library(tidyr)
View(trends)
re_trends <- trends %>%
gather("year", "homcides", 3:27)
View(re_trends)
re_trends <- trends %>%
gather("year", "homicides", 3:27) %>%
group_by(year) %>%
summarize(total(sum(homcides, na.rm=T)))
re_trends <- trends %>%
gather("year", "homicides", 3:27) %>%
group_by(year) %>%
summarize(total=sum(homcides, na.rm=T))
re_trends <- trends %>%
gather("year", "homicides", 3:27) %>%
group_by(year) %>%
summarize(total=sum(homicides, na.rm=T))
View(re_trends)
library(kable)
kable(re_trends)
library(knitr)
kable(re_trends)
str(re_trends)
re_trends$percent_change <- 0
for (i in 2:nrow(re_trends)) {
re_trends$percent_change[i] <- round((re_trends$total[i]-re_trends$total[i-1])/re_trends$total[i-1]*100,2)
}
View(re_trends)
ggplot(re_trends, aes(x=year, y=percent_change)) +geom_bar(stat="identity")
library(ggplot2)
ggplot(re_trends, aes(x=year, y=percent_change)) +geom_bar(stat="identity")
percent_change_2015
ggplot(re_trends, aes(x=year, y=total)) +geom_bar(stat="identity")
sum(h2015_joined$Homicides2015, na.rm=T)
View(trends)
View(trends)
View(h2015)
165-88
77/88
*100
dc <- filter(trends, State=="DC")
View(dc)
dc <- filter(trends, State=="DC") %>%
gather("Year", "Total", 3:27)
View(dc)
dc <- rbind(dc, data.frame(Agency="Washington Metropolitan Police Dept", State="DC", Year="X2015", Total=105))
View(dc)
dc <- filter(trends, State=="DC") %>%
gather("Year", "Total", 3:27)
# Adding the 2015 data
dc <- rbind(dc, data.frame(Agency="Washington Metropolitan Police Dept", State="DC", Year="X2015", Total=162))
dc <- filter(trends, State=="DC") %>%
gather("Year", "Total", 3:27)
# Adding the 2015 data
dc <- rbind(dc, data.frame(Agency="Washington Metropolitan Police Dept", State="DC", Year="X2015", Total=162))
dc$Year <- gsub("X", "", dc$Year)
ggplot(dc, aes(x=Year, y=Total)) +geom_bar(stat="identity")
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
View(h2015)
chi <- filter(trends, Agency=="Chicago Police Dept") %>%
gather("Year", "Total", 3:27)
# Adding the 2015 data
chi <- rbind(chi, data.frame(Agency="Chicago Police Dept", State="IL", Year="X2015", Total=478))
chi$Year <- gsub("X", "", chi$Year)
ggplot(chi, aes(x=Year, y=Total)) +geom_bar(stat="identity")
View(h2015)
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
h2015 <- arrange(h2015, desc(Population))
h2015 <- select(h2015, State, City, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015$per_capita <- round(h2015$Homicides2015/h2015$Population*100,2)
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
# Arranging by population in descending order
h2015 <- arrange(h2015, desc(Population))
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter)
h2015$per_capita <- round(h2015$Homicides2015/h2015$Population*100,2)
h2015 <- arrange(h2015, desc(per_capita))
datatable(h2015)
library(DT)
datatable(h2015)
View(h2015)
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter) %>%
filter(!is.na(City))
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
h2015 <- arrange(h2015, desc(Population))
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter) %>%
filter(!is.na(City))
h2015$per_capita <- round(h2015$Homicides2015/h2015$Population*100,2)
h2015 <- arrange(h2015, desc(per_capita))
datatable(h2015)
h2015$per_capita <- round(h2015$Homicides2015/h2015$Population*100000,2)
h2015 <- arrange(h2015, desc(per_capita))
datatable(h2015)
h2015 <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter) %>%
filter(!is.na(City)) %>%
filter(Population>100000)
h2015 <- read_excel("data/Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2015.xls", sheet=1, skip=3)
colnames(h2015) <- make.names(colnames(h2015))
# For every row between 1 and the the total number of rows in h2015 dataframe
for (i in 1:nrow(h2015)) {
# If the cell in State is blank,
if(is.na(h2015$State[i])) {
# Then fill it with the value of the State cell previous to it
h2015$State[i]<-h2015$State[i-1]
}
}
h2015 <- arrange(h2015, desc(Population))
h2015b <- select(h2015, State, City, Population, Homicides2015=Murder.and.nonnegligent.manslaughter) %>%
filter(!is.na(City)) %>%
filter(Population>100000)
h2015b$per_capita <- round(h2015b$Homicides2015/h2015b$Population*100000,2)
h2015b <- arrange(h2015b, desc(per_capita))
datatable(h2015b)
